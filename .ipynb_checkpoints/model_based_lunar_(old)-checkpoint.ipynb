{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxPu9WEsykrI"
      },
      "source": [
        "# Learning Lunar Lander Transition Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO8QiXBQykrM"
      },
      "source": [
        "The objective of this project is to learn the transition function of the lunar lander environment and use that to learn the optimal policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrlxCJcO5Gpa",
        "outputId": "7a9646e1-892d-46e5-954a-2aaa3e6cd1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.11/dist-packages (4.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install swig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade setuptools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuSafn0m2Nqh",
        "outputId": "8335fd7c-c4cd-4cca-d259-48e7599512f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3dQUksl4r_9",
        "outputId": "369e3e04-f3b9-42ef-ac32-a1866aba32f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.21.0 (from gym[box2d]==0.21.0)\n",
            "  Using cached gym-0.21.0.tar.gz (1.5 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install gym[box2d]==0.21.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR2kYL3B3Quw",
        "outputId": "0f834863-49d4-4e6d-df5e-4194b08968bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.8.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB6iqzDsIMf7",
        "outputId": "79be8bb6-0156-4420-f03c-7e36f0bc5a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.4.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<1.1.0,>=0.29.1->stable-baselines3)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.4.1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, stable-baselines3\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 stable-baselines3-2.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppjvirVwJhjd",
        "outputId": "ecba9ac2-447b-45a1-e94d-8678d27af3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy>=2.0\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install 'shimmy>=2.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8w8lcOiXykrP"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z5jQ1aaDIkOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd287b89-7e85-49c5-e175-a185f86e7738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n"
          ]
        }
      ],
      "source": [
        "import stable_baselines3\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.ppo import MlpPolicy\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJtXXo5lykrT"
      },
      "source": [
        "## Loading Lunar Lander Train and Test environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "7jta_Cb_ykrU",
        "outputId": "30b102bb-3475-427e-eefc-b5dbad0bb515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DependencyNotInstalled",
          "evalue": "box2D is not installed, run `pip install gym[box2d]`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/box2d/bipedal_walker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mBox2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     from Box2D.b2 import (\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Box2D'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a548c521ead7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the Lunar Lander environment for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLander-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the Lunar Lander environment for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLander-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Assume it's a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0menv_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"render_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/box2d/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbipedal_walker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBipedalWalker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBipedalWalkerHardcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcar_racing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarRacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlunar_lander\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLunarLander\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLunarLanderContinuous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/box2d/bipedal_walker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mDependencyNotInstalled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"box2D is not installed, run `pip install gym[box2d]`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDependencyNotInstalled\u001b[0m: box2D is not installed, run `pip install gym[box2d]`"
          ]
        }
      ],
      "source": [
        "# Load the Lunar Lander environment for training\n",
        "train_env = gym.make('LunarLander-v2')\n",
        "\n",
        "# Load the Lunar Lander environment for testing\n",
        "test_env = gym.make('LunarLander-v2')\n",
        "\n",
        "print(\"Training and testing environments loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2T38n-iykrW"
      },
      "source": [
        "## Sample Episode and Create Transition Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7MnMLxqykrX"
      },
      "source": [
        "**TODO**\n",
        "\n",
        "Check the following dataset generation process. Think about why we are generating this data? What does this tuple (state, action, next_state) mean?\n",
        "We want to train a NN model which predicts next_state given the input state and action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON-y16JAykrY"
      },
      "outputs": [],
      "source": [
        "# Function to sample state-action-state pairs\n",
        "def sample_transition_data(env, num_episodes=100):\n",
        "    data = []\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = env.action_space.sample()\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            data.append((state, action, next_state))\n",
        "            state = next_state\n",
        "    return data\n",
        "\n",
        "# Sample data from the training environment\n",
        "transition_data = sample_transition_data(train_env)\n",
        "\n",
        "# Convert the data to a structured format (e.g., numpy array or pandas dataframe)\n",
        "transition_data_np = np.array(transition_data, dtype=object)\n",
        "\n",
        "print(\"Sampled transition data successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SBxUyUkykra",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "transition_data_pd = pd.DataFrame(transition_data)\n",
        "transition_data_pd.columns = ['state', 'action', 'next_state']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsuGfzNm8ujh"
      },
      "outputs": [],
      "source": [
        "transition_data_pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yYXuMwXgZ4H"
      },
      "outputs": [],
      "source": [
        "transition_data_pd.to_csv('transition_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub2dB_Qvykrb"
      },
      "outputs": [],
      "source": [
        "transition_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz814SSlykrb"
      },
      "source": [
        "**Why we are generating this data:**  \n",
        "- As we want to train a Neural Network model to predict next_state given the input state and action, these data including (state, action, next_state) serves as a real observed value for our training/validating/testing data set to build our neural network.\n",
        "\n",
        "**The meaning of the tuple (state, action, next_action):**\n",
        "- state: The current state that the lunar lander is in. It is an array consisting of 8 parameters: the coordinates of the lander in x & y, its linear velocities in x & y, its angle, its angular velocity, and two booleans that represent whether each leg is in contact with the ground or not. (Source: Lunar lander - Gymnasium Documentation)\n",
        "- action: The action that the lunar lander takes. It can be one of 4 actions: 0: do nothing; 1: fire left orientation engine; 2: fire main engine; 3: fire right orientation engine (Source: Lunar lander - Gymnasium Documentation)\n",
        "- next_state: The observed state that the lunar lander is in after taking an action. It also has 8 parameters, same as State\n",
        "- (state, action) is used as our **input** for our neural network: We know exactly which state we are in, and we can choose which action to do next\n",
        "- next_state is our real observed **output** after we take an action from our previous state.\n",
        "- Together they form an input/output pair to be used to train our neural network model.\n",
        "\n",
        "**The purpose of training this neural network:**\n",
        "- The purpose of training this neural network is to accurately predict which state the lunar lander will be if it takes certain action\n",
        "- This would aid us in choosing the action that leads to the best next state to maximize our reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6STc0_CYykrc"
      },
      "source": [
        "## Train NN for transition function of lunar lander"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WOBy82pykrc"
      },
      "source": [
        "**TODO**\n",
        "\n",
        "1. Write a simple NN using PyTorch (learn how to write one).\n",
        "2. The NN should take (state, action) as input and it should output (next_state)\n",
        "3. Plot train and test accuracy of the NN model\n",
        "4. Change the Data generation process i.e. instead of sampling random action, can we use some heuristic for action so that the dataset we generate is good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtnUfmC0m3GE"
      },
      "source": [
        "### Data Preparation ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F454uESYidWf"
      },
      "outputs": [],
      "source": [
        "#Separate input and output variables\n",
        "X = transition_data_pd[['state', 'action']]\n",
        "y = transition_data_pd['next_state']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfeHb_YMkxJn"
      },
      "outputs": [],
      "source": [
        "#Concatenate action to state for more convenient datatype\n",
        "# Step 1: Concatenate state and action for each row\n",
        "def concat_state_action(row):\n",
        "    return np.append(row[\"state\"], row[\"action\"])\n",
        "\n",
        "# Apply the concatenation function to each row\n",
        "X = X.apply(concat_state_action, axis=1)\n",
        "\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzhy6MiQjDX0"
      },
      "outputs": [],
      "source": [
        "#Convert to numpy arrays\n",
        "X = X.values #Array of array\n",
        "y = y.values #Array of array\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1MQgnfcmJZr"
      },
      "outputs": [],
      "source": [
        "#Convert to 2D array\n",
        "X = np.stack(X)\n",
        "y = np.stack(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-6xRlJ90QbK"
      },
      "outputs": [],
      "source": [
        "#Check if need Normalization\n",
        "print(np.mean(X, axis = 0))\n",
        "print(np.std(X, axis = 0))\n",
        "print(np.mean(y, axis = 0))\n",
        "print(np.std(y, axis = 0))\n",
        "\n",
        "#All are in similar magnitude --> Not really need normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNn6O08Lf3iN"
      },
      "outputs": [],
      "source": [
        "#Train-test split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2NfAbkyiVFT"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g457qcmujAKB"
      },
      "outputs": [],
      "source": [
        "#Convert to Tensor Float\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_test = torch.FloatTensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWB0Wuol0SqH"
      },
      "outputs": [],
      "source": [
        "def getNewData(X = X, y = y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  X_train = torch.FloatTensor(X_train)\n",
        "  X_test = torch.FloatTensor(X_test)\n",
        "  y_train = torch.FloatTensor(y_train)\n",
        "  y_test = torch.FloatTensor(y_test)\n",
        "  return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQoerDWDnXQC"
      },
      "source": [
        "### Train the Model ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03VL9D4_6uFS"
      },
      "source": [
        "**Build the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZGNsSuaykrd"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features = 1, h1 = 10, h2 = 15, out_feature = 1):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.out = nn.Linear(h2, out_feature)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq_TNdGCqA82"
      },
      "outputs": [],
      "source": [
        "model = Model(in_features = 9, h1 = 10, h2 = 15, out_feature = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZm6r4mSkvxA"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nik1uF7oSG3"
      },
      "outputs": [],
      "source": [
        "print(model.parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbGt8L7a0l5B"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = getNewData(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADTzLGMHowTr"
      },
      "outputs": [],
      "source": [
        "epochs = 1000\n",
        "losses = []\n",
        "test_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    y_pred = model.forward(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    losses.append(loss.detach().numpy())\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f'epoch: {i:2}  loss: {losses[i]}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljhAg9Fkro0T"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(epochs), losses, label = \"Train Loss\", color = \"blue\")\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iZ-WHCR9JI-"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    y_eval = model.forward(torch.FloatTensor([1,0.5,0.05,1,0.5,1,1,0.5,1]))\n",
        "    loss = criterion(y_eval, y_test)\n",
        "\n",
        "print(y_eval.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1F0Sip9ykrd"
      },
      "source": [
        "## Create Custom Gym Environment with Trained NN\n",
        "\n",
        "**TODO** Write a custom gym environment which use the above NN model as transition function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQWtRaa15T_0"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "class CustomLunarLander(gym.Env):\n",
        "    def __init__(self, model, original_env):\n",
        "        super(CustomLunarLander, self).__init__()\n",
        "        self.model = model\n",
        "        self.original_env = original_env\n",
        "        self.action_space = self.original_env.action_space\n",
        "        self.observation_space = self.original_env.observation_space\n",
        "        self.state = self.original_env.reset()\n",
        "        self.prev_shaping = None\n",
        "        self.time_limit = 10000\n",
        "        self.cur_time = 0\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        terminated = False\n",
        "        self.cur_time += 1\n",
        "        '''\n",
        "        if self.cur_time >= self.time_limit:\n",
        "            self.original_env.game_over = True\n",
        "            terminated = True\n",
        "        '''\n",
        "\n",
        "        original_env.step(action)\n",
        "\n",
        "        state = self.state\n",
        "        state_action = np.append(state, action)\n",
        "        state_action_tensor = torch.FloatTensor(state_action)\n",
        "\n",
        "        #Update state using Neural Network\n",
        "\n",
        "        with torch.no_grad():\n",
        "            state_tensor = self.model.forward(state_action_tensor)\n",
        "            state = state_tensor.numpy()\n",
        "            self.state = state\n",
        "\n",
        "        #Original reward function from openai github:\n",
        "\n",
        "        #Main engine firing: less reward for more engine usage\n",
        "        m_power = 0.0\n",
        "        if (self.original_env.continuous and action[0] > 0.0) or (\n",
        "            not self.original_env.continuous and action == 2\n",
        "        ):\n",
        "            # Main engine\n",
        "            if self.original_env.continuous:\n",
        "                m_power = (np.clip(action[0], 0.0, 1.0) + 1.0) * 0.5  # 0.5..1.0\n",
        "                assert m_power >= 0.5 and m_power <= 1.0\n",
        "            else:\n",
        "                m_power = 1.0\n",
        "\n",
        "        #Side engine firing: less reward for more engine usage\n",
        "        s_power = 0.0\n",
        "        if (self.original_env.continuous and np.abs(action[1]) > 0.5) or (\n",
        "            not self.original_env.continuous and action in [1, 3]\n",
        "        ):\n",
        "            # Orientation engines\n",
        "            if self.original_env.continuous:\n",
        "                direction = np.sign(action[1])\n",
        "                s_power = np.clip(np.abs(action[1]), 0.5, 1.0)\n",
        "                assert s_power >= 0.5 and s_power <= 1.0\n",
        "            else:\n",
        "                direction = action - 2\n",
        "                s_power = 1.0\n",
        "\n",
        "\n",
        "        reward = 0\n",
        "        shaping = (\n",
        "            -100 * np.sqrt(self.state[0] * self.state[0] + self.state[1] * self.state[1])\n",
        "            - 100 * np.sqrt(self.state[2] * self.state[2] + self.state[3] * self.state[3])\n",
        "            - 100 * abs(self.state[4])\n",
        "            + 10 * self.state[6]\n",
        "            + 10 * self.state[7]\n",
        "        )  # And ten points for legs contact, the idea is if you\n",
        "        # lose contact again after landing, you get negative reward\n",
        "        if self.prev_shaping is not None:\n",
        "            reward = shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        reward -= (\n",
        "            m_power * 0.30\n",
        "        )  # less fuel spent is better, about -30 for heuristic landing\n",
        "        reward -= s_power * 0.03\n",
        "\n",
        "\n",
        "        self.original_env.unwrapped.state = self.state\n",
        "        if self.original_env.game_over or abs(state[0]) >= 1.0:\n",
        "            terminated = True\n",
        "            reward = -100\n",
        "        if not self.original_env.lander.awake:\n",
        "            terminated = True\n",
        "            reward = +100\n",
        "\n",
        "        if self.original_env.render_mode == \"human\":\n",
        "            self.original_env.render()\n",
        "        return np.array(state, dtype=np.float32), reward, terminated, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.original_env.reset()\n",
        "        #self.cur_time = 0\n",
        "        self.prev_shaping = None\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.original_env.render(mode)\n",
        "\n",
        "#Reference: OpenAI/gym github for original environment source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w3rtMuC9-K9"
      },
      "outputs": [],
      "source": [
        "original_env = gym.make('LunarLander-v2')\n",
        "custom_env = CustomLunarLander(model, original_env)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Return type of custom_env should be similar to original_env\n",
        "#Do some random sample collection using sample_transition_data\n",
        "#(Optional) : Lunar lander landing"
      ],
      "metadata": {
        "id": "XwV3b5U-axKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQhvDBKtykrd"
      },
      "source": [
        "## Train a policy using stable-baseline3 using above created custom gym environment\n",
        "\n",
        "**TODO** train a policy using PPO or SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag7Njh3dIp_K"
      },
      "outputs": [],
      "source": [
        "rl_model = PPO(MlpPolicy, custom_env, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha7ckpqxykre"
      },
      "source": [
        "## Test the policy on test_env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCos97YWykre"
      },
      "source": [
        "Report the results you get and the training/test plot. Put the results in the word file, you will reuse the reported results when writing the URECA report."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, env, num_episodes=100, deterministic=True):\n",
        "    \"\"\"\n",
        "    Evaluate a RL agent\n",
        "    :param model: (BaseRLModel object) the RL Agent\n",
        "    :param num_episodes: (int) number of episodes to evaluate it\n",
        "    :return: (float) Mean reward for the last num_episodes\n",
        "    \"\"\"\n",
        "    # This function will only work for a single Environment\n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes):\n",
        "        print(\"Current episode: \", i)\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        obs = env.reset()\n",
        "        while not done:\n",
        "            action, _states = model.predict(obs, deterministic=deterministic)\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            episode_rewards.append(reward)\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    print(\"Mean reward:\", mean_episode_reward, \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return mean_episode_reward\n",
        "\n",
        "mean_reward = evaluate(rl_model, custom_env, num_episodes=3)\n",
        "print(f\"Mean reward: {mean_reward:.2f}\")"
      ],
      "metadata": {
        "id": "p_3oxG2A2pIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rl_model.learn(total_timesteps = 10000)"
      ],
      "metadata": {
        "id": "eAtX7bMd2v6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_reward = evaluate(rl_model, test_env, num_episodes=3)\n",
        "print(f\"Mean reward: {mean_reward:.2f}\")"
      ],
      "metadata": {
        "id": "6_1Ndqk_D740"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "control_model = PPO(MlpPolicy, custom_env, verbose=1)"
      ],
      "metadata": {
        "id": "JgUC4jyHMsq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_reward = evaluate(control_model, test_env, num_episodes=3)\n",
        "print(f\"Mean reward: {mean_reward:.2f}\")"
      ],
      "metadata": {
        "id": "1Suf_RCKM76P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBvGKj2MM-T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C00-g08rcCPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging face is the hyper parameter to train the model using the original lunar lander environment ==> First step before testing the transition function learning"
      ],
      "metadata": {
        "id": "QVeDGY2fcCqe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}